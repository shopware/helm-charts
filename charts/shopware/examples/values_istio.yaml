# This is more off an advanced configuration and is just an example.
useIstio: true
region: eu-central-1

percona:
  # You can disable Percona and use your own database. Just modify the storage database
  # part in this file.
  # TODO: Not tested yet, database part is not variable
  enabled: true

  # The version for Percona to use. This is also the image version for the percona-xtradb-cluster
  version: 1.14.0
  # Allows only one database and allows to overwrite the topologySpreadConstraints
  allowUnsafeConfigurations: false

  database:
    version: "8.0"
    # These are the default values for the data
    size: 3

    # You can overwrite these default values from Percona. To see which values are valid check
    # the Percona documentation on this: https://github.com/percona/percona-helm-charts/blob/main/charts/pxc-db/values.yaml
    # If there are values missing for you, add them to the template and make a PR.
    resources:
      requests:
        memory: 4Gi
        cpu: 1000m
      limits:
        memory: 8Gi
        cpu: 1200m
    annotations:
      sidecar.istio.io/inject: "false"
    # affinity:
    serviceAnnotations:
      sidecar.istio.io/inject: "false"
    storageClassName: gp3
    storageSize: 50Gi

    # We overwrite the topologySpreadConstraints for this to schedule only one database
    topologySpreadConstraints:

  # This is only useful if you want more performance since the sql-proxy is using connection-pooling.
  proxy:
    enabled: true

    # You can overwrite these default values from Percona. To see which values are valid check
    # the Percona documentation on this: https://github.com/percona/percona-helm-charts/blob/main/charts/pxc-db/values.yaml
    # If there are values missing for you, add them to the template and make a PR.
    # size: 1
    # annotations:
    resources:
      requests:
        memory: 1Gi
        cpu: 1000m
      limits:
        memory: 1Gi
        cpu: 1500m
    # topologySpreadConstraints:
    # affinity:
    annotations:
      sidecar.istio.io/inject: "false"
    serviceAnnotations:
      "sidecar.istio.io/inject": "false"
    storageClassName: gp2
    storageSize: 10G

store:
  # We use traefik.me to resolve to 127.0.0.1
  # Enter your DNS name for the shop.
  # This will make sure that your sales-channel is set up correctly and the ingress is using the host address.
  host: localhost.traefik.me

  # blackfire:
  #   enabled: false
  #   host: blackfire
  #   port: 8707

  otel:
    enabled: true
    exporterEndpoint: http://opentelemetry-collector.opentelemetry-collector.svc.cluster.local:4317

  # You can define a Monolog configuration here.
  # Please refer to the official Monolog documentation for details.
  # This configuration will be mounted in the deployment as a ConfigMap.
  # The configuration file is located at /var/www/html/config/packages/monolog.yaml
  monolog:
    handlers:
      main:
        type: fingers_crossed
        action_level: info
        handler: nested
        excluded_http_codes: [404, 405]
        buffer_size: 50
      nested:
        type: group
        members: [stderr, file_log]
      stderr:
        type: stream
        path: php://stderr
        level: info
      file_log:
        type: stream
        path: "/var/log/shopware.log"
        level: info
        formatter: 'monolog.formatter.json'
      console:
        type: console
        process_psr_3_messages: false
        channels: ["!event", "!doctrine"]
      business_event_handler_buffer:
        level: info

  container:
    # This image is used for the setup job and the deployment. If you want to migrate to a new
    # version just update this and the operator makes sure to handle the migrations.
    image: ghcr.io/shopware/shopware-kubernetes:latest
    # imagePullPolicy: IfNotPresent
    # restartPolicy: Always
    replicas: 2
    # progressDeadlineSeconds: 30
    # topologySpreadConstraints:
    # affinity:
    # nodeSelector:
    imagePullSecrets:
      - name: regcred
    resources:
      requests:
        memory: 2Gi
        cpu: 1000m
      limits:
        memory: 2Gi
        cpu: 1500m

  # You need to set the correct ingressClassName for this to work properly. If you follow
  # the Readme and use kind, you can use nginx as ingress class and everything should run
  # out of the box.
  network:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt
      nginx.ingress.kubernetes.io/backend-protocol: HTTP
      nginx.ingress.kubernetes.io/service-upstream: "true"

  # You can run commands before and after the /setup is executed.
  setupHook:
    after: curl -fsI -X POST http://localhost:15020/quitquitquit

  horizontalPodAutoscaler:
    enabled: true
    minReplicas: 1
    maxReplicas: 10
    behavior:
      scaleDown:
        policies:
          - type: Pods
            value: 1
            periodSeconds: 60
    metrics:
      - type: Pods
        pods:
          metric:
            name: phpfpm_process_utilization
          target:
            averageValue: "50"
            type: AverageValue

rustfs:
  enabled: true
  mode:
    distributed:
      enabled: true
    standalone:
      enabled: false
  replicaCount: 4
  storageClassName: gp3
  storageSize: 10Gi
  ingress:
    enabled: true
    className: nginx
    annotations:
      cert-manager.io/cluster-issuer: letsencrypt
      nginx.ingress.kubernetes.io/proxy-body-size: '0'
      nginx.ingress.kubernetes.io/service-upstream: "true"
      nginx.ingress.kubernetes.io/ssl-redirect: "true"

# This is used by Shopware to map the aws secret into our cluster to pull images
regcred:
  clusterStore:
    name: aws-secrets
  aws:
    name: github-regcred

redissession:
  enabled: false
  architecture: standalone
  master:
    resources:
      requests:
        memory: 500Mi
        cpu: 1000m
      limits:
        memory: 1Gi
        cpu: 1000m
  auth:
    enabled: false

redisapp:
  enabled: true
  architecture: standalone
  master:
    resources:
      requests:
        memory: 500Mi
        cpu: 1000m
      limits:
        memory: 1Gi
        cpu: 1000m
  auth:
    enabled: false

redisqueue:
  enabled: false
  architecture: standalone
  master:
    resources:
      requests:
        memory: 500Mi
        cpu: 1000m
      limits:
        memory: 1Gi
        cpu: 2000m
  auth:
    enabled: false

blackfire:
  image: blackfire/blackfire:latest
  serverID: id
  serverToken: token
  # port: 8307
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 512Mi
      cpu: 100m

# This controls the Shopware operator helm chart which can be found here:
shopware-operator:
  # Disabling makes sense if you want to test the Operator itself
  enabled: false

grafana:
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          uid: prometheus
          url: http://shopware-prometheus-server.shopware-redstone-staging.svc.cluster.local
        - name: Loki
          type: loki
          url: http://loki-gateway.loki.svc.cluster.local

prometheus:
  prometheus-node-exporter:
    enabled: false

promtail:
  daemonset:
    enabled: false
  deployment:
    enabled: true
  config:
    clients:
      - url: http://loki-gateway.loki.svc.cluster.local/loki/api/v1/push
  server:
    remoteWrite:
      - url: http://mimir-nginx.mimir.svc:80/api/v1/push
